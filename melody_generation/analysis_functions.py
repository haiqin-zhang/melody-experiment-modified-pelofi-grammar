import numpy as np
import pandas as pd
import pickle

#organizes the list of melody so that it's easier to count occurrences
#corpus: a 2-d list of melodies generated in markov_melody
def cleanup_corpus(corpus):
  for item in corpus:
    while len(item) < 15:
      item.append('0')

  a = np.array(corpus)
  a = a.flatten()
  a = [i for i in a if i != '0']

  return a

#IC calculator takes  a corpus (ie a list of generated melodies) and calculates IC of each note
  #doesn't take the context into account - use IC_context for that
  #clean up corpus with cleanup_corpus before using the calculator
#corpus: a 1-D list of melodies generated with markov_melody and processed using cleanup_corpus; all melodies in the set are concatenated 
#returns an dictionary with the IC of each note used, IC = -log2(p)
def IC(corpus):

  unique, counts = np.unique(corpus, return_counts=True)
  occurrences = dict(zip(unique, counts))
  total = sum(occurrences.values())
  IC_dict = {key: -np.log2(value/total) for key, value in occurrences.items()}

  df = pd.DataFrame.from_dict(IC_dict, orient = 'index', columns=[ 'Probs'])
  df.sort_index()

  return df

#IC_context calculates the probability of a note n given the previous context note c. It should resemble the artificial grammar map.
#corpus: a 1-D list of melodies generated by markov_melody and processed with cleanup_corpus
#returns dictionary where keys are the context, note; values are probabilities of note given context
def IC_context_prob(corpus):

  pairs = list(zip(corpus, corpus[1:])) #puts everything into consecutive pairs
  pairs = [''.join(item) for item in pairs]
  unique, counts = np.unique(pairs, return_counts=True)
  occurrences_pairs = dict(zip(unique, counts))

  context_prob = []
  for notepair in pairs:
  
    p_nc = occurrences_pairs[notepair]
    unique, counts = np.unique(corpus, return_counts=True)
    occurrences_notes = dict(zip(unique, counts))

    if notepair[1] == '#' or notepair[1] =='b':
      p_c = occurrences_notes[notepair[:3]]
    else:
      p_c = occurrences_notes[notepair[:2]]


    p_ngivenc = p_nc / p_c 
    context_prob.append(p_ngivenc)


  prob = dict(zip(pairs,context_prob))
  #print(prob)
  df = pd.DataFrame.from_dict(prob, orient = 'index', columns=['Transition probs'])
  sorted_df = df.sort_index()

  return sorted_df

#IC_context extends IC_context_prob by calculating the IC of a note in a given context: -log2(p(n|c))
def IC_context(corpus):
  IC = IC_context_prob(corpus)
  #print(IC)
  for item in IC.index:
    #print(IC['Transition probs'][item])
    IC['Transition probs'][item] = -np.log2(IC['Transition probs'][item])

  sorted_IC = IC.sort_index()
  return sorted_IC
